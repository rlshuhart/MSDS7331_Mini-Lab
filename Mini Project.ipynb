{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MSDS 7331 - Mini-Project: SVM&LR Classification\n",
    "## Team: Dineen Parker, Dale Legband, Ryan Shuhart\n",
    "collaboration site: https://github.com/rlshuhart/MSDS7331_Mini-Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM and Logistic Regression Modeling  \n",
    "* [50 points] Create a logistic regression model and a support vector machine model for the classiﬁcation task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is ﬁne to use. \n",
    "* [10 points] Discuss the advantages of each model for each classiﬁcation task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efﬁciency? Explain in detail.  \n",
    "* [30 points] Use the weights from logistic regression to interpret the importance of different features for each classiﬁcation task. Explain your interpretation in detail. Why do you think some variables are more important? \n",
    "* [10 points] Look at the chosen support vectors for the classiﬁcation task. Do these provide any insight into the data? Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Modules Used ###\n",
    "\n",
    "# Data manipulation: pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization: seaborn and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in preprocessed data from previous assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random but useful fact: if the first record in a csv file is \n",
    "# \"ID\" than Excel will interpret it as a SYLK file\n",
    "# https://annalear.ca/2010/06/10/why-excel-thinks-your-csv-is-a-sylk/\n",
    "\n",
    "data_url = \"https://raw.githubusercontent.com/rlshuhart/MSDS7331_Project_1/master/cc_data/cc_data_processed.csv\"\n",
    "#data_url = \"../MSDS7331_Project_1/cc_data/cc_data_processed.csv\"\n",
    "\n",
    "cc_data = pd.read_csv(data_url, index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 1 to 30000\n",
      "Data columns (total 27 columns):\n",
      "LIMIT_BAL                     30000 non-null int64\n",
      "SEX                           30000 non-null object\n",
      "EDUCATION                     30000 non-null object\n",
      "MARRIAGE                      30000 non-null object\n",
      "AGE                           30000 non-null int64\n",
      "PAY_0_Sept                    30000 non-null int64\n",
      "PAY_2_Aug                     30000 non-null int64\n",
      "PAY_3_July                    30000 non-null int64\n",
      "PAY_4_June                    30000 non-null int64\n",
      "PAY_5_May                     30000 non-null int64\n",
      "PAY_6_April                   30000 non-null int64\n",
      "BILL_AMT1_Sept                30000 non-null int64\n",
      "BILL_AMT2_Aug                 30000 non-null int64\n",
      "BILL_AMT3_July                30000 non-null int64\n",
      "BILL_AMT4_June                30000 non-null int64\n",
      "BILL_AMT5_May                 30000 non-null int64\n",
      "BILL_AMT6_April               30000 non-null int64\n",
      "PAY_AMT1_Sept                 30000 non-null int64\n",
      "PAY_AMT2_Aug                  30000 non-null int64\n",
      "PAY_AMT3_July                 30000 non-null int64\n",
      "PAY_AMT4_June                 30000 non-null int64\n",
      "PAY_AMT5_May                  30000 non-null int64\n",
      "PAY_AMT6_April                30000 non-null int64\n",
      "default payment next month    30000 non-null int64\n",
      "AGE_range                     30000 non-null object\n",
      "LIMIT_BAL_range               30000 non-null object\n",
      "Default_Yes_No                30000 non-null object\n",
      "dtypes: int64(21), object(6)\n",
      "memory usage: 6.4+ MB\n",
      "None\n",
      "\n",
      "Index(['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0_Sept',\n",
      "       'PAY_2_Aug', 'PAY_3_July', 'PAY_4_June', 'PAY_5_May', 'PAY_6_April',\n",
      "       'BILL_AMT1_Sept', 'BILL_AMT2_Aug', 'BILL_AMT3_July', 'BILL_AMT4_June',\n",
      "       'BILL_AMT5_May', 'BILL_AMT6_April', 'PAY_AMT1_Sept', 'PAY_AMT2_Aug',\n",
      "       'PAY_AMT3_July', 'PAY_AMT4_June', 'PAY_AMT5_May', 'PAY_AMT6_April',\n",
      "       'default payment next month', 'AGE_range', 'LIMIT_BAL_range',\n",
      "       'Default_Yes_No'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(cc_data.info())\n",
    "print()\n",
    "print(cc_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Preprocessing of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 1 to 30000\n",
      "Data columns (total 26 columns):\n",
      "EDUCATION                     30000 non-null int64\n",
      "PAY_0_Sept                    30000 non-null int64\n",
      "PAY_2_Aug                     30000 non-null int64\n",
      "PAY_3_July                    30000 non-null int64\n",
      "PAY_4_June                    30000 non-null int64\n",
      "PAY_5_May                     30000 non-null int64\n",
      "PAY_6_April                   30000 non-null int64\n",
      "BILL_AMT1_Sept                30000 non-null int64\n",
      "BILL_AMT2_Aug                 30000 non-null int64\n",
      "BILL_AMT3_July                30000 non-null int64\n",
      "BILL_AMT4_June                30000 non-null int64\n",
      "BILL_AMT5_May                 30000 non-null int64\n",
      "BILL_AMT6_April               30000 non-null int64\n",
      "PAY_AMT1_Sept                 30000 non-null int64\n",
      "PAY_AMT2_Aug                  30000 non-null int64\n",
      "PAY_AMT3_July                 30000 non-null int64\n",
      "PAY_AMT4_June                 30000 non-null int64\n",
      "PAY_AMT5_May                  30000 non-null int64\n",
      "PAY_AMT6_April                30000 non-null int64\n",
      "default payment next month    30000 non-null int64\n",
      "AGE_range                     30000 non-null int64\n",
      "LIMIT_BAL_range               30000 non-null int64\n",
      "isMale                        30000 non-null bool\n",
      "Marriage_Married              30000 non-null float64\n",
      "Marriage_Others               30000 non-null float64\n",
      "Marriage_Single               30000 non-null float64\n",
      "dtypes: bool(1), float64(3), int64(22)\n",
      "memory usage: 6.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# makeing copy of data to retain original input for now. \n",
    "# Have to add .copy() or any change will reflect in the original too.\n",
    "cc_data_processed = cc_data.copy()\n",
    "\n",
    "cats = ['SEX', 'EDUCATION', 'MARRIAGE','AGE_range', 'LIMIT_BAL_range']\n",
    "\n",
    "# SEX convert to isMale\n",
    "cc_data_processed['isMale'] = cc_data['SEX']=='Male'\n",
    "\n",
    "# Two options for Education: \n",
    "# If treating ordinal then keep single columnn but label in numerical order\n",
    "# if nominal then create dummy variables.\n",
    "# Trying ordinal first with 'Others' as the highest. Previous exploration\n",
    "# showed this group have better rates of default which continued the trend\n",
    "# of more education means less likely to default:\n",
    "cc_data_processed['EDUCATION'] = cc_data['EDUCATION'].apply({'High School':0,\n",
    "                                                             'University':1,\n",
    "                                                             'Graduate School':2, \n",
    "                                                             'Others':3}.get)\n",
    "\n",
    "# Marriage is nominal category therefore converting to dummies\n",
    "\n",
    "cc_data_processed = pd.concat((cc_data_processed, \n",
    "                               pd.get_dummies(cc_data['MARRIAGE'], prefix='Marriage')), \n",
    "                               axis=1)\n",
    "\n",
    "# Age range is ordinal category:\n",
    "cc_data_processed['AGE_range'] = cc_data['AGE_range'].apply({'21-30':0,\n",
    "                                                             '31-40':1,\n",
    "                                                             '41-50':2, \n",
    "                                                             '51-60':3,\n",
    "                                                             '61-70':4,\n",
    "                                                             '71-80+':5}.get)\n",
    "# Limit_Bal_Range is ordingal\n",
    "cc_data_processed['LIMIT_BAL_range'] = cc_data['LIMIT_BAL_range'].apply({'0-250k':0,\n",
    "                                                                         '>250k-500k':1,\n",
    "                                                                         '>500k-750k':2,\n",
    "                                                                         '>750k':3}.get)\n",
    "\n",
    "# Drop unused features:\n",
    "# 'Default_Yes_No' - Used for visualization labeling only and same as 'default payment next month'\n",
    "# 'AGE' - Using Age_range instead, may bring back\n",
    "cc_data_processed.drop(['Default_Yes_No','AGE', 'SEX','MARRIAGE', 'LIMIT_BAL'], axis=1, inplace=True)\n",
    "print(cc_data_processed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc_data_target = cc_data_processed['default payment next month'].values\n",
    "cc_data_Xs = cc_data_processed.drop('default payment next month', axis='columns').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models should have an accuracy better than predicting all non-defaults of 77.9%\n"
     ]
    }
   ],
   "source": [
    "# Sample Default Rate\n",
    "sample_d_rt = (1 - cc_data_target.sum() / len(cc_data_target))*100\n",
    "print(\"The sample default rate is: %.1f%%\"  % sample_d_rt)\n",
    "\n",
    "# The sample default rate is the same as predicting all zeros (or no defaults)\n",
    "all_zeros = np.zeros(len(cc_data_target))\n",
    "all_zero_score = mt.accuracy_score(cc_data_target,all_zeros)*100\n",
    "print(\"The models should have an accuracy better than predicting all non-defaults of %.1f%%\"  % all_zero_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7799  0.7827  0.7826]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "model = LogisticRegression(penalty='l2', C=1.0, class_weight=None)\n",
    "\n",
    "def classify(model, X, y):\n",
    "    accuracies = cross_val_score(model,X,y=y) \n",
    "    print(accuracies)\n",
    "\n",
    "    \n",
    "classify(model, cc_data_Xs, cc_data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2', C=1.0, class_weight=None)\n",
    "model.fit(cc_data_Xs,cc_data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77880000000000005"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.accuracy_score(cc_data_target,all_zeros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
